<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Arka Roy</title>
 <link href="http://localhost:4000/feed.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2023-11-02T02:26:33+05:30</updated>
 <id>http://localhost:4000/</id>
 <author>
   <name>Arka Roy</name>
   <email>arka.nitdgp14@gmail.com</email>
 </author>

 
 <entry>
   <title>How does Spark Processing Start ?</title>
   <link href="http://localhost:4000/2020/10/03/spark-submit/"/>
   <updated>2020-10-03T00:00:00+05:30</updated>
   <id>http://localhost:4000/2020/10/03/spark-submit</id>
   <content type="html">&lt;ul&gt;
  &lt;li&gt;What happens when a jar is submitted through a Spark Client ?&lt;/li&gt;
  &lt;li&gt;How does a spark job gets triggered ?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lets-deep-dive-&quot;&gt;Let’s deep dive !!&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;A client program (spark-submit) submits the application, including the necessary specifications to run the application-specific &lt;strong&gt;ApplicationMaster&lt;/strong&gt; (for Spark Applications - SparkMaster).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ResourceManager gets responsibility for the allocation of a necessary container in which ApplicationMaster(SparkMaster) will be started. Then ResourceManager starts the ApplicationMaster(SparkMaster).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;SparkMaster is created at the same time as the Driver on the same node(in case of cluster mode) when the user submits the spark application using spark-submit. The Driver informs the Application Master about the executor’s requirements for the application and the Application Master negotiates the resources with the Resource Manager to host these executors.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ApplicationMaster registers itself in ResourceManager. Registration allows the Customer program (spark-submit) to request specific information from ResourceManager that allows it to directly interact with its ApplicationMaster.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ApplicationMaster asks for suitable containers from ResourceManager for the application to run. After successfully receiving the containers, ApplicationMaster launches them, providing NodeManager(s) their configurations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inside the containers, it runs the user application code. The NodeManager(s) then provides the information (execution phase, status) for ApplicationMaster.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;During the runtime of the user application, the client interacts with ApplicationMaster to obtain the application status.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When the application completes and all necessary work is completed, ApplicationMaster deregisters from ResourceManager and terminates, releasing the container for other purposes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Once the driver is up it runs the main program of the user application code. The first thing it does is create a SparkContext. So let us understand that in detail.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</content>
   <author>
     <name>Arka Roy</name>
     <uri>http://localhost:4000</uri>
   </author>   
 </entry>
 
 <entry>
   <title>Spark on Yarn</title>
   <link href="http://localhost:4000/2020/10/01/spark-yarn/"/>
   <updated>2020-10-01T00:00:00+05:30</updated>
   <id>http://localhost:4000/2020/10/01/spark-yarn</id>
   <content type="html">&lt;p&gt;What it is like to run Apache Spark on a  &lt;strong&gt;Yarn Cluster&lt;/strong&gt; ?
How does it increase the efficiency of the nodes and reduces the cost ?
What is Yarn for that matter ?&lt;/p&gt;

&lt;p&gt;Let’s find out through some visuals and pointers !&lt;/p&gt;

&lt;h3 id=&quot;important-concepts-and-their-relations&quot;&gt;Important Concepts and their relations&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://snipboard.io/gkaB82.jpg&quot; alt=&quot;drawing&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;how-are-resource-manager-and-node-manager-related-&quot;&gt;How are Resource Manager and Node Manager related ?&lt;/h3&gt;

&lt;p&gt;In cluster-mode, the resource allocation has the structure shown below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://snipboard.io/aMeilB.jpg&quot; alt=&quot;drawing&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;concepts-in-bits-&quot;&gt;Concepts in bits !&lt;/h3&gt;

&lt;h4 id=&quot;resource-manager&quot;&gt;Resource Manager&lt;/h4&gt;
&lt;p&gt;ResourceManager is the ultimate authority that decides the allocation of resources between all applications in the system. It has minions that run on all nodes of the cluster called NodeManager. Also, ResourceManager has a plug-in component scheduler that is responsible for allocating resources for various running applications.
The yarn container which runs the Spark Driver is also called Spark AM (Application Master)&lt;/p&gt;

&lt;h4 id=&quot;yarn-container&quot;&gt;Yarn Container&lt;/h4&gt;
&lt;p&gt;Containers are computing units, a kind of wrappers for node resources to perform tasks of a user application. They are the main computing units that are managed by YARN. Containers have their own parameters that can be configured on-demand (e.g. ram, CPU, etc.).&lt;/p&gt;

&lt;h4 id=&quot;node-manager&quot;&gt;Node Manager&lt;/h4&gt;
&lt;p&gt;Containers on each node are controlled by NodeManager daemon&lt;/p&gt;

&lt;h4 id=&quot;application-master&quot;&gt;Application Master&lt;/h4&gt;
&lt;p&gt;When launching a new application on a cluster, ResourceManager allocates one container for ApplicationMaster. ApplicationMaster for each application is a framework-specific entity that is tasked with negotiating resources with ResourceManager and working with NodeManager(s) to perform and monitor component tasks
ApplicationMaster will be responsible for the entire lifecycle of the distributed application.&lt;/p&gt;

&lt;h4 id=&quot;language-agnostic&quot;&gt;Language Agnostic&lt;/h4&gt;
&lt;p&gt;ResourceManager, NodeManager, and the container do not care about the type of application or task. All application framework code is simply transferred to the ApplicationMaster so that any distributed framework can be supported by YARN — as long as someone implements a suitable ApplicationMaster for it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://snipboard.io/1lQXPE.jpg&quot; alt=&quot;drawing&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

</content>
   <author>
     <name>Arka Roy</name>
     <uri>http://localhost:4000</uri>
   </author>   
 </entry>
 
 
</feed>
